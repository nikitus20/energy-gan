{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from model import Discriminator, Generator, initialize_weights\n",
    "\n",
    "# Hyperparameters etc\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "LEARNING_RATE = 5e-5\n",
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = 64\n",
    "CHANNELS_IMG = 1\n",
    "Z_DIM = 128\n",
    "NUM_EPOCHS = 5\n",
    "FEATURES_CRITIC = 64\n",
    "FEATURES_GEN = 64\n",
    "CRITIC_ITERATIONS = 5\n",
    "WEIGHT_CLIP = 0.01\n",
    "\n",
    "transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            [0.5 for _ in range(CHANNELS_IMG)], [0.5 for _ in range(CHANNELS_IMG)]\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = datasets.MNIST(root=\"dataset/\", transform=transforms, download=True)\n",
    "#comment mnist and uncomment below if you want to train on CelebA dataset\n",
    "#dataset = datasets.ImageFolder(root=\"celeb_dataset\", transform=transforms)\n",
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# initialize gen and disc/critic\n",
    "gen = Generator(Z_DIM, CHANNELS_IMG, FEATURES_GEN).to(device)\n",
    "critic = Discriminator(CHANNELS_IMG, FEATURES_CRITIC).to(device)\n",
    "initialize_weights(gen)\n",
    "initialize_weights(critic)\n",
    "\n",
    "# initializate optimizer\n",
    "opt_gen = optim.RMSprop(gen.parameters(), lr=LEARNING_RATE)\n",
    "opt_critic = optim.RMSprop(critic.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# for tensorboard plotting\n",
    "fixed_noise = torch.randn(32, Z_DIM, 1, 1).to(device)\n",
    "writer_real = SummaryWriter(f\"logs/real\")\n",
    "writer_fake = SummaryWriter(f\"logs/fake\")\n",
    "step = 0\n",
    "\n",
    "gen.train()\n",
    "critic.train()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Target labels not needed! <3 unsupervised\n",
    "    for batch_idx, (data, _) in enumerate(tqdm(loader)):\n",
    "        data = data.to(device)\n",
    "        cur_batch_size = data.shape[0]\n",
    "\n",
    "        # Train Critic: max E[critic(real)] - E[critic(fake)]\n",
    "        for _ in range(CRITIC_ITERATIONS):\n",
    "            noise = torch.randn(cur_batch_size, Z_DIM, 1, 1).to(device)\n",
    "            fake = gen(noise)\n",
    "            critic_real = critic(data).reshape(-1)\n",
    "            critic_fake = critic(fake).reshape(-1)\n",
    "            loss_critic = -(torch.mean(critic_real) - torch.mean(critic_fake))\n",
    "            critic.zero_grad()\n",
    "            loss_critic.backward(retain_graph=True)\n",
    "            opt_critic.step()\n",
    "\n",
    "            # clip critic weights between -0.01, 0.01\n",
    "            for p in critic.parameters():\n",
    "                p.data.clamp_(-WEIGHT_CLIP, WEIGHT_CLIP)\n",
    "\n",
    "        # Train Generator: max E[critic(gen_fake)] <-> min -E[critic(gen_fake)]\n",
    "        gen_fake = critic(fake).reshape(-1)\n",
    "        loss_gen = -torch.mean(gen_fake)\n",
    "        gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        # Print losses occasionally and print to tensorboard\n",
    "        if batch_idx % 100 == 0 and batch_idx > 0:\n",
    "            gen.eval()\n",
    "            critic.eval()\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(loader)} \\\n",
    "                  Loss D: {loss_critic:.4f}, loss G: {loss_gen:.4f}\"\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake = gen(noise)\n",
    "                # take out (up to) 32 examples\n",
    "                img_grid_real = torchvision.utils.make_grid(\n",
    "                    data[:32], normalize=True\n",
    "                )\n",
    "                img_grid_fake = torchvision.utils.make_grid(\n",
    "                    fake[:32], normalize=True\n",
    "                )\n",
    "\n",
    "                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n",
    "                writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n",
    "\n",
    "            step += 1\n",
    "            gen.train()\n",
    "            critic.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
