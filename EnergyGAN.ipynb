{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from model import EnergyDistanceDiscriminator, Generator, initialize_weights\n",
    "\n",
    "def main():\n",
    "    # Setup device\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # Hyperparameters\n",
    "    config = {\n",
    "        \"lr\": 5e-5,\n",
    "        \"batch_size\": 200,\n",
    "        \"image_size\": 64,\n",
    "        \"channels_img\": 1,\n",
    "        \"z_dim\": 128,\n",
    "        \"num_epochs\": 20,\n",
    "        \"features_gen\": 64,\n",
    "        \"weight_clip\": 0.01,  # Note: Weight clipping is not used in ED discriminator\n",
    "    }\n",
    "\n",
    "    # Data preprocessing\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(config[\"image_size\"]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5])\n",
    "    ])\n",
    "\n",
    "    # Load Dataset\n",
    "    dataset = datasets.MNIST(root=\"dataset/\", transform=transform, download=True)\n",
    "    loader = DataLoader(dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "\n",
    "    # Initialize models\n",
    "    gen = Generator(config[\"z_dim\"], config[\"channels_img\"], config[\"features_gen\"]).to(device)\n",
    "    critic = EnergyDistanceDiscriminator(config[\"channels_img\"]).to(device)\n",
    "    initialize_weights(gen)\n",
    "    #initialize_weights(critic)  # Assuming EnergyDistanceDiscriminator also has weights\n",
    "\n",
    "    # Optimizers\n",
    "    opt_gen = optim.RMSprop(gen.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "    # TensorBoard\n",
    "    writer_loss = SummaryWriter(f\"logs_egan/losses\")\n",
    "    step = 0\n",
    "\n",
    "    # Adapt models for multiple GPUs\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "        gen = nn.DataParallel(gen)\n",
    "        critic = nn.DataParallel(critic)\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(config[\"num_epochs\"]):\n",
    "        for batch_idx, (data, _) in enumerate(tqdm(loader)):\n",
    "            data = data.to(device)\n",
    "            cur_batch_size = data.shape[0]\n",
    "\n",
    "            # Generate fake images\n",
    "            noise = torch.randn(cur_batch_size, config[\"z_dim\"], 1, 1).to(device)\n",
    "            fake = gen(noise)\n",
    "\n",
    "            # Train Generator with Energy Distance\n",
    "            loss_gen = critic(data, fake)\n",
    "            gen.zero_grad()\n",
    "            loss_gen.backward()\n",
    "            opt_gen.step()\n",
    "\n",
    "            # Log the generator loss\n",
    "            writer_loss.add_scalar(\"Loss/ED\", loss_gen.item(), global_step=step)\n",
    "\n",
    "            # Periodically log and visualize the training progress\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f\"Epoch [{epoch}/{config['num_epochs']}] Batch {batch_idx}/{len(loader)} Batch Size: {cur_batch_size}, loss G: {loss_gen:.4f}\")\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    fake = gen(noise)\n",
    "                    img_grid_real = torchvision.utils.make_grid(data[:32], normalize=True)\n",
    "                    img_grid_fake = torchvision.utils.make_grid(fake[:32], normalize=True)\n",
    "                    writer_loss.add_image(\"Real Images\", img_grid_real, global_step=step)\n",
    "                    writer_loss.add_image(\"Fake Images\", img_grid_fake, global_step=step)\n",
    "\n",
    "                step += 1\n",
    "\n",
    "            # Reset models to training mode\n",
    "            gen.train()\n",
    "            #critic.train()  # Assuming the critic might need to switch between modes for certain types\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
