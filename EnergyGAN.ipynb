{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from model import EnergyDistanceDiscriminator, Generator, initialize_weights\n",
    "\n",
    "# Hyperparameters etc\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "LEARNING_RATE = 5e-5\n",
    "BATCH_SIZE = 200\n",
    "IMAGE_SIZE = 64\n",
    "CHANNELS_IMG = 1\n",
    "Z_DIM = 128\n",
    "NUM_EPOCHS = 20\n",
    "FEATURES_CRITIC = 64\n",
    "FEATURES_GEN = 64\n",
    "CRITIC_ITERATIONS = 5\n",
    "WEIGHT_CLIP = 0.01\n",
    "\n",
    "transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            [0.5 for _ in range(CHANNELS_IMG)], [0.5 for _ in range(CHANNELS_IMG)]\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = datasets.MNIST(root=\"dataset/\", transform=transforms, download=True)\n",
    "#comment mnist and uncomment below if you want to train on CelebA dataset\n",
    "#dataset = datasets.ImageFolder(root=\"celeb_dataset\", transform=transforms)\n",
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# initialize gen and disc/critic\n",
    "gen = Generator(Z_DIM, CHANNELS_IMG, FEATURES_GEN).to(device)\n",
    "critic = EnergyDistanceDiscriminator(CHANNELS_IMG).to(device)\n",
    "initialize_weights(gen)\n",
    "#initialize_weights(critic)\n",
    "\n",
    "# initializate optimizer\n",
    "opt_gen = optim.RMSprop(gen.parameters(), lr=LEARNING_RATE)\n",
    "#opt_critic = optim.RMSprop(critic.parameters(), lr=LEARNING_RATE) -> no optimizer in critic\n",
    "\n",
    "# for tensorboard plotting\n",
    "fixed_noise = torch.randn(32, Z_DIM, 1, 1).to(device)\n",
    "writer_real = SummaryWriter(f\"logs_egan/real\")\n",
    "writer_fake = SummaryWriter(f\"logs_egan/fake\")\n",
    "writer_loss = SummaryWriter(f\"logs_egan/losses\")\n",
    "step = 0\n",
    "\n",
    "gen.train()\n",
    "#critic.train()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Target labels not needed! <3 unsupervised\n",
    "    for batch_idx, (data, _) in enumerate(tqdm(loader)):\n",
    "        data = data.to(device)\n",
    "        cur_batch_size = data.shape[0]\n",
    "\n",
    "        # Train Critic: max E[critic(real)] - E[critic(fake)]\n",
    "#         for _ in range(CRITIC_ITERATIONS):\n",
    "#             noise = torch.randn(cur_batch_size, Z_DIM, 1, 1).to(device)\n",
    "#             fake = gen(noise)\n",
    "#             critic_real = critic(data).reshape(-1)\n",
    "#             critic_fake = critic(fake).reshape(-1)\n",
    "#             loss_critic = -(torch.mean(critic_real) - torch.mean(critic_fake))\n",
    "#             critic.zero_grad()\n",
    "#             loss_critic.backward(retain_graph=True)\n",
    "#             opt_critic.step()\n",
    "\n",
    "#             # clip critic weights between -0.01, 0.01\n",
    "#             for p in critic.parameters():\n",
    "#                 p.data.clamp_(-WEIGHT_CLIP, WEIGHT_CLIP)\n",
    "                \n",
    "        noise = torch.randn(4*cur_batch_size, Z_DIM, 1, 1).to(device)\n",
    "        fake = gen(noise)\n",
    "        # Train Generator: max E[critic(gen_fake)] <-> min -E[critic(gen_fake)]\n",
    "        # We actually need min critic(real, fake)\n",
    "        loss_gen = critic(data, fake)\n",
    "        gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "        writer_loss.add_scalar(\"Loss/ED\", loss_gen.item(), global_step=step)\n",
    "        # gen_fake = critic(fake).reshape(-1)\n",
    "        # loss_gen = -torch.mean(gen_fake)\n",
    "        # gen.zero_grad()\n",
    "        # loss_gen.backward()\n",
    "        # opt_gen.step()\n",
    "\n",
    "        # Print losses occasionally and print to tensorboard\n",
    "        if batch_idx % 100 == 0 and batch_idx > 0:\n",
    "            gen.eval()\n",
    "            critic.eval()\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {batch_idx}/{len(loader)} \\\n",
    "                  Batch Size: {cur_batch_size}, loss G: {loss_gen:.4f}\"\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake = gen(noise)\n",
    "                # take out (up to) 32 examples\n",
    "                img_grid_real = torchvision.utils.make_grid(\n",
    "                    data[:32], normalize=True\n",
    "                )\n",
    "                img_grid_fake = torchvision.utils.make_grid(\n",
    "                    fake[:32], normalize=True\n",
    "                )\n",
    "\n",
    "                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n",
    "                writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n",
    "\n",
    "            step += 1\n",
    "            gen.train()\n",
    "            #critic.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!tensorboard --logdir=logs --port=6006\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d8a01a-1f81-44b9-94c0-99c68fd47e59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
